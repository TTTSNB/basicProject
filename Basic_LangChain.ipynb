{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEARNING LANGCHAIN BY USING LANGCHAIN (PYTHON)\n",
    "===============================================\n",
    "\n",
    "BY: ELLIOTT RISCH\n",
    "\n",
    "DATE: 2023-10-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before you begin, you will need to create a .env file in the same directory as this notebook. \n",
    "# The .env file should contain the following lines, with your own api keys filled in:\n",
    "\n",
    "OPENAI_API_KEY=\"sk-XXXXXX\"\n",
    "\n",
    "PINECONE_ENV=\"xx-xxxxx-xxx-free\"\n",
    "\n",
    "PINECONE_API_KEY=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "\n",
    "# You should also have installed the required packages in requirements.txt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I. SETTING UP AND USING --> ChatOpenAI***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Find and load the .env file containing the relevant api keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv # for .env file\n",
    "load_dotenv(find_dotenv()) # load environment variables from .env file\n",
    "\n",
    "# Should read \"True\" below, if the .env file was loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2:** Run a quick test query to assure that the OpenAI API key has been loaded correctly from the .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLarge language models use large amounts of data to learn the probability of a word given its context in a given language.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI # Import the model class\n",
    "llm = OpenAI(model_name=\"text-davinci-003\") # Create a new model instance\n",
    "llm(\"explain large language models in one sentence\") # Call the model with a prompt\n",
    "\n",
    "# See the system's response below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3:** Call the class imports necessary to talk with a OpenAI chat model, i.e., GPT-3 or GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import( # \"Schema\" here means the mode of communication between the human and the system.\n",
    "    AIMessage,  # What the system says to you. \n",
    "    HumanMessage, # What you use to pose your prompt to the system.\n",
    "    SystemMessage, # What you use to tell the system it's role.\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI # From langchain's chat_models module, we will import the ChatOpenAI class to go with the chosen schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 4:** Create a new instance of the OpenAI chat model class, create a list of the components of the chat, and then call the chat function to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.3) # Create a new chat instance\n",
    "messages = [ # Create a list of messages to send to the system\n",
    "        SystemMessage(content=\"You are an expert data scientist.\"), # Tell the system it's role\n",
    "        HumanMessage(content=\"Write a python script that trains a neural network on simulated data.\") # Pose a prompt to the system\n",
    "]\n",
    "response = chat(messages) # Send the messages to the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 4:** Display the system's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's an example of a Python script that trains a neural network on simulated data using the Keras library:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(1000, 10)\n",
      "y = np.random.randint(2, size=(1000, 1))\n",
      "\n",
      "# Define the model architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(32, input_dim=10, activation='relu'))\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=10, batch_size=32)\n",
      "\n",
      "# Evaluate the model\n",
      "loss, accuracy = model.evaluate(X, y)\n",
      "print(f\"Loss: {loss}\")\n",
      "print(f\"Accuracy: {accuracy}\")\n",
      "```\n",
      "\n",
      "In this script, we first generate simulated data using `numpy`. We create a random matrix `X` of shape `(1000, 10)` and a random binary vector `y` of shape `(1000, 1)`.\n",
      "\n",
      "Then, we define the neural network model using `Sequential` from Keras. The model consists of two dense layers, with 32 units in the first layer and 1 unit in the output layer. The activation function for the first layer is ReLU, and the activation function for the output layer is sigmoid.\n",
      "\n",
      "Next, we compile the model using the binary cross-entropy loss function and the Adam optimizer.\n",
      "\n",
      "We then train the model using the `fit` function, specifying the number of epochs and the batch size.\n",
      "\n",
      "Finally, we evaluate the model on the training data using the `evaluate` function and print the loss and accuracy.\n"
     ]
    }
   ],
   "source": [
    "print(response.content,end='\\n') # Print the system's response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***II. SETTING UP AND USING --> PromptTemplates***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:** Call the class imports necessary to talk with a OpenAI chat model and to use the PromptTemplates class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI # Import the model class\n",
    "from langchain import PromptTemplate # Import the PromptTemplate class, which allows you to create prompts with variables.\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models.\n",
    "Explain the concept {concept} in a couple of sentences.\n",
    "\"\"\" # Create a template for a prompt, with a variable \"concept\" that can be filled in later.\n",
    "\n",
    "prompt = PromptTemplate( # Create a new prompt instance\n",
    "    input_variables=[\"concept\"], # Specify the variables that will be filled in\n",
    "    template=template, # Specify the template to use\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2:** Print the prompt template for the chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['concept'], output_parser=None, partial_variables={}, template='\\nYou are an expert data scientist with an expertise in building deep learning models.\\nExplain the concept {concept} in a couple of sentences.\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt # Print the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3:** Define the llm and send the prompt template to the chat model with a variable value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGradient descent is an optimization algorithm used to find the values of parameters (coefficients) of a function that minimizes a cost function. It works by iteratively computing the partial derivatives of the cost function with respect to the parameters and updating the parameters in the negative direction of the gradient of the cost function with respect to the parameters.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\") # Create a new model instance\n",
    "llm(prompt.format(concept=\"gradient descent\")) # Call the model with the prompt, with the variable filled in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***III. SETTING UP AND USING --> Chains***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:** Make a chain call to the chat model using the prompt template that we have already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient descent is an optimization algorithm used to find the set of parameters that minimize a given cost function. It works by iteratively updating the parameters in the direction of the negative gradient of the cost function with respect to the parameters. The magnitude of the updates is determined by a parameter called the learning rate.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain # Import the LLMChain class, which allows you to chain together multiple language model calls.\n",
    "\n",
    "chain = LLMChain( # Create a new chain instance\n",
    "    llm=llm, # Specify the language model to use\n",
    "    prompt=prompt, # Specify the prompt to use\n",
    ")\n",
    "\n",
    "# run the chain only specifying the input variable.\n",
    "print(chain.run(\"gradient descent\")) # Call the chain with the input variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2:** Add a new link to the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Turn this({ml_concept}) concept description into a 500 word explanation that a five year old child would understand.\" # Specify the template\n",
    "\n",
    "second_prompt = PromptTemplate( # Create a new prompt instance\n",
    "    input_variables=[\"ml_concept\"], # Specify the variables that will be filled in\n",
    "    template=template, # Specify the template to use\n",
    ")   \n",
    "\n",
    "chain_two = LLMChain( # Create a new chain instance \n",
    "    llm=llm, # Specify the language model to use\n",
    "    prompt=second_prompt, # Specify the prompt to use\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3:** Combine the two links of the chain into a single chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "Gradient descent is an iterative optimization algorithm used to minimize a function by adjusting the parameters of a model according to the direction of the gradient of the loss function with respect to the model parameters. It is an important technique for optimizing deep learning models by finding the optimal set of parameters that minimize the loss function and improve the model's performance.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Gradient descent is like a game where you have to find the best way down a mountain. You have to try different paths to see which one is the fastest way to the bottom.\n",
      "\n",
      "You start at the top of the mountain. You can see the bottom, but it's a long way down. You don't know the best way to get there, so you have to try different paths.\n",
      "\n",
      "For each path, you need to keep track of how long it takes you to get down the mountain. You also need to make sure you don't get lost and end up in the wrong place.\n",
      "\n",
      "At the end of each path, you compare the time you took with the time it took to go down the other paths. The fastest path is the one with the shortest time.\n",
      "\n",
      "Gradient descent is like this game, but instead of a mountain, it is used to find the best way to make a model work better. The model is like a mountain, and the parameters are like the paths that you can take down the mountain. \n",
      "\n",
      "The model has a loss function which tells you how well the model is doing. This is like the timer that tells you how long it takes you to get down each path.\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain # Import the SimpleSequentialChain class, which allows you to chain together multiple language model calls.\n",
    "\n",
    "sequential_chain = SimpleSequentialChain( # Create a new chain instance\n",
    "    chains=[chain, chain_two], # Specify the chains to use\n",
    "    verbose=True, # Specify whether to print the intermediate results\n",
    ")\n",
    "\n",
    "# run the chain only specifying the input variable for the first chain.\n",
    "explanation = sequential_chain.run(\"gradient descent\") # Call the chain with the input variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IV. SETTING UP AND USING --> Embeddings and Vector Stores***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Call the class imports necessary to recursively split the text into chunks and then split up the text into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # Import the RecursiveCharacterTextSplitter class, which allows you to split text into smaller chunks.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter( # Create a new text splitter instance\n",
    "    chunk_size = 100, # Specify the maximum length of the chunks\n",
    "    chunk_overlap = 0, # Specify the overlap between chunks\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([explanation]) # Split the text into chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Check out the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Gradient descent is like a game where you have to find the best way down a mountain. You have to try', metadata={}),\n",
       " Document(page_content='different paths to see which one is the fastest way to the bottom.', metadata={}),\n",
       " Document(page_content=\"You start at the top of the mountain. You can see the bottom, but it's a long way down. You don't\", metadata={}),\n",
       " Document(page_content='know the best way to get there, so you have to try different paths.', metadata={}),\n",
       " Document(page_content='For each path, you need to keep track of how long it takes you to get down the mountain. You also', metadata={}),\n",
       " Document(page_content=\"need to make sure you don't get lost and end up in the wrong place.\", metadata={}),\n",
       " Document(page_content='At the end of each path, you compare the time you took with the time it took to go down the other', metadata={}),\n",
       " Document(page_content='paths. The fastest path is the one with the shortest time.', metadata={}),\n",
       " Document(page_content='Gradient descent is like this game, but instead of a mountain, it is used to find the best way to', metadata={}),\n",
       " Document(page_content='make a model work better. The model is like a mountain, and the parameters are like the paths that', metadata={}),\n",
       " Document(page_content='you can take down the mountain.', metadata={}),\n",
       " Document(page_content='The model has a loss function which tells you how well the model is doing. This is like the timer', metadata={}),\n",
       " Document(page_content='that tells you how long it takes you to get down each path.', metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts # Print the chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Extract the plain text from the individual elements of the list with the page_content variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gradient descent is like a game where you have to find the best way down a mountain. You have to try'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].page_content # Print the first chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Import and then create a new instance of the OpenAIEmbeddings class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings # Import the OpenAIEmbeddings class, which allows you to create embeddings from text.\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model_name=\"ada\") # Create a new embeddings instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Call \"embed_query\" on the raw text value of the first page_content variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.015347131240837595,\n",
       " 0.006830774119852393,\n",
       " 0.030486165906851145,\n",
       " 0.041140715753248555,\n",
       " -0.013089282193277384,\n",
       " 0.04711309359742752,\n",
       " -0.0028795380537913863,\n",
       " 0.019030442105339277,\n",
       " 0.021392341302956624,\n",
       " -0.03662501952077325,\n",
       " -0.048569767758550715,\n",
       " -0.0448656483541537,\n",
       " 0.02592884886929494,\n",
       " 0.008386296994550813,\n",
       " 0.00504374354954852,\n",
       " -0.0387059852690137,\n",
       " 0.043908401502259935,\n",
       " 0.03610477528974547,\n",
       " 0.004000659025864782,\n",
       " 0.017032714241970403,\n",
       " 0.034460812162371006,\n",
       " -0.033711663747946395,\n",
       " 0.04711309359742752,\n",
       " 0.013411831791122398,\n",
       " 0.02865491567587053,\n",
       " 0.024368123626792047,\n",
       " -0.010212345789049514,\n",
       " 0.034564863243750694,\n",
       " -0.0060504114986009465,\n",
       " -0.023369259695107607,\n",
       " -0.008578786465961438,\n",
       " -0.031922034322046676,\n",
       " 0.011143578007953242,\n",
       " 0.04940215778313713,\n",
       " -0.0011289246401954246,\n",
       " 0.02948730197516671,\n",
       " 0.029404064090295133,\n",
       " 0.041182334695684344,\n",
       " -0.030028353814767268,\n",
       " -0.014389886251588943,\n",
       " 0.01222568075583181,\n",
       " 0.0002477651240982619,\n",
       " 0.012121632468419786,\n",
       " 0.04049561842020365,\n",
       " 0.00834467712079247,\n",
       " 0.0027780909502816004,\n",
       " -0.05252360826814291,\n",
       " 0.008797287776394429,\n",
       " -0.02413921758075011,\n",
       " 0.0031864807810536196,\n",
       " -0.00419054731337317,\n",
       " 0.012517016146849982,\n",
       " -0.0010443853484654966,\n",
       " 0.03115207643640418,\n",
       " -0.019633924221238636,\n",
       " -0.07116906956801583,\n",
       " 0.05115016826660106,\n",
       " 0.028530056985918054,\n",
       " -0.06925458331480876,\n",
       " 0.04103666839715909,\n",
       " -0.00435702448010015,\n",
       " 0.0047003840148243355,\n",
       " 0.015752920586199294,\n",
       " 0.010904267226302358,\n",
       " -0.04278468260591325,\n",
       " -0.009161457247997787,\n",
       " -0.0030148010136915268,\n",
       " -0.04361706890520943,\n",
       " 0.019030442105339277,\n",
       " -0.015066200585428367,\n",
       " 0.018260486082341893,\n",
       " 0.06788114331326689,\n",
       " 0.04197310205254474,\n",
       " -0.007512290821496291,\n",
       " 0.011559771157601331,\n",
       " 0.010789814203281388,\n",
       " -0.0015880379063070169,\n",
       " 0.016699760839839,\n",
       " -0.0019053853691781966,\n",
       " -0.009894997627686416,\n",
       " -0.006653891751855188,\n",
       " -0.019363397370115797,\n",
       " -0.02576237123690668,\n",
       " -0.047362807252042234,\n",
       " 0.005085362957645585,\n",
       " 0.040162663155427124,\n",
       " -0.0014800877266263198,\n",
       " -0.02022699973888393,\n",
       " -0.02111140971622484,\n",
       " -0.023306829418808815,\n",
       " 0.01436907678037105,\n",
       " 0.035959108991220214,\n",
       " -0.021288292084222046,\n",
       " -0.041182334695684344,\n",
       " 0.017875507139520644,\n",
       " 0.008152188580704402,\n",
       " -0.006872393527949458,\n",
       " -0.026136945444118983,\n",
       " -0.017469716862836385,\n",
       " 0.022828207855507047,\n",
       " -0.0036833115629936017,\n",
       " -0.030590215125585723,\n",
       " -0.004242571457079181,\n",
       " -0.0011094155280980107,\n",
       " 0.019998091830196876,\n",
       " 0.06642446542685347,\n",
       " -0.028509247514700162,\n",
       " -0.008786883040785483,\n",
       " -0.06022318339927768,\n",
       " -0.014410696654129394,\n",
       " 0.028488438043482268,\n",
       " 0.03202608167813614,\n",
       " 0.02424326493683957,\n",
       " -0.049735109322623414,\n",
       " 0.05664392082218802,\n",
       " 0.01252742088245893,\n",
       " -5.3609287440160244e-05,\n",
       " -0.0008031232132266563,\n",
       " -0.043950024169985946,\n",
       " 0.0709609748558369,\n",
       " 3.279961613343656e-05,\n",
       " 0.013848835343310937,\n",
       " 0.027864148319010136,\n",
       " 0.0379360273833712,\n",
       " 0.0012869479592401358,\n",
       " 0.01706392844879724,\n",
       " -0.012142441939637679,\n",
       " 0.00943718553560254,\n",
       " -0.023702213097239012,\n",
       " 0.030673453010457298,\n",
       " 0.05389704454439454,\n",
       " -0.009510018684865167,\n",
       " 0.0013331194391661145,\n",
       " -0.022578492338247214,\n",
       " -0.0030590213728601888,\n",
       " -0.004757610526334819,\n",
       " -0.033441140622113785,\n",
       " 0.05252360826814291,\n",
       " 0.0797426536661728,\n",
       " -0.007553910229593355,\n",
       " 0.027406334364281144,\n",
       " 0.02380626231597359,\n",
       " 0.0333162800695162,\n",
       " -0.03751983423372311,\n",
       " 0.012652279572411402,\n",
       " 0.08169876631239611,\n",
       " -0.008146985281577371,\n",
       " 0.03450243110480679,\n",
       " -0.016096278723939643,\n",
       " -0.025138081512434546,\n",
       " -0.013536690481074871,\n",
       " -0.033794905358108196,\n",
       " -0.013817621136484099,\n",
       " 0.009140647776779892,\n",
       " 0.06842219701551257,\n",
       " -0.023951930477143956,\n",
       " -0.054771049786126506,\n",
       " -0.009624472639208691,\n",
       " 0.0494853956680087,\n",
       " -0.007168931286772105,\n",
       " 0.025720752294470895,\n",
       " 0.01318292574508046,\n",
       " -0.05040101985217645,\n",
       " 0.0497767282650592,\n",
       " 0.00017493129089563332,\n",
       " -0.045240222561366,\n",
       " -0.07383271168622796,\n",
       " -0.007158526551163159,\n",
       " 0.021808534452604715,\n",
       " 0.009811759742814844,\n",
       " 0.01816684159921626,\n",
       " 0.0038471877786489844,\n",
       " -0.044532693089377184,\n",
       " 0.020039712635277776,\n",
       " 0.015243082953425573,\n",
       " -0.03094397799893502,\n",
       " 0.025616703075736314,\n",
       " -0.016231542149501062,\n",
       " -0.029404064090295133,\n",
       " 0.015149439401622496,\n",
       " 0.09147930719177133,\n",
       " 0.014993367436165741,\n",
       " 0.017958745024392216,\n",
       " 0.007814030948123411,\n",
       " -0.0037717527469922044,\n",
       " -0.004112510864983513,\n",
       " 0.07291708005147976,\n",
       " -0.028592485399571734,\n",
       " -0.03106883668888749,\n",
       " -0.0014020515110673031,\n",
       " 0.01315171153825362,\n",
       " -0.013526285745465924,\n",
       " -0.03691635584311398,\n",
       " 0.03412785689759448,\n",
       " -0.017032714241970403,\n",
       " -0.05035940090974066,\n",
       " -0.01925935001402633,\n",
       " -0.0015724306864782773,\n",
       " -0.03450243110480679,\n",
       " -0.02149638865904609,\n",
       " 0.01707433318440619,\n",
       " 0.03287927744865022,\n",
       " 0.0015321119867476507,\n",
       " 0.03325385165586252,\n",
       " -0.016606116356713368,\n",
       " 0.03953837156830988,\n",
       " 0.04353382729504763,\n",
       " -0.022724158636772466,\n",
       " 0.0020770651365402894,\n",
       " -0.011674225111944858,\n",
       " 0.03265037326525339,\n",
       " -0.03113126510254117,\n",
       " 0.04107828733959488,\n",
       " 0.006123245113524851,\n",
       " 0.007418647269693214,\n",
       " 0.02977863829750744,\n",
       " -0.0333162800695162,\n",
       " -0.019061658174811234,\n",
       " 0.03435676480628154,\n",
       " 0.031464222229962806,\n",
       " -0.050317781967304874,\n",
       " 0.005225828285350199,\n",
       " -0.0271982377894571,\n",
       " -0.012433777330655853,\n",
       " -0.050484257737048024,\n",
       " -0.00792848397114438,\n",
       " -0.03901813106257232,\n",
       " -0.007741197333199507,\n",
       " -0.02557508413330053,\n",
       " 0.05851679185824954,\n",
       " 0.05606125190279679,\n",
       " -0.04669690044777943,\n",
       " 0.009239493696387442,\n",
       " 0.029820257239943224,\n",
       " 0.020039712635277776,\n",
       " 0.02784333884779224,\n",
       " -0.0016504669020372942,\n",
       " 0.019228133944554377,\n",
       " 0.019540279738113002,\n",
       " 0.02075764498023043,\n",
       " -0.004973511118526853,\n",
       " -0.036000727933656,\n",
       " -0.024701078891568563,\n",
       " 0.034877005312019094,\n",
       " -0.05264846509545027,\n",
       " 0.02075764498023043,\n",
       " -0.00019265201630068487,\n",
       " 0.008505952385376256,\n",
       " 0.01784429107004869,\n",
       " 0.0725008906271219,\n",
       " -0.009379958558430778,\n",
       " -0.01768822003591449,\n",
       " 0.05006806458739993,\n",
       " -0.06284519912447357,\n",
       " 0.014431506125347287,\n",
       " -0.004533906848097355,\n",
       " -0.05502076716603145,\n",
       " -0.018062794243126793,\n",
       " 0.017448907391618494,\n",
       " 0.0032176952207110983,\n",
       " -0.012392158388220068,\n",
       " 0.025387797029694376,\n",
       " 0.03548048742791845,\n",
       " -0.08228143150649711,\n",
       " -0.022391205234641064,\n",
       " 0.007522695557105237,\n",
       " -0.028342769882311904,\n",
       " 0.056269346614975714,\n",
       " 0.048653009368712516,\n",
       " 0.013130902067035728,\n",
       " 0.018021173438045893,\n",
       " 0.04010023474177345,\n",
       " 0.020809670520920278,\n",
       " 0.02363978468358533,\n",
       " 0.014473125067783072,\n",
       " 0.005597801308660266,\n",
       " 0.05377218771708718,\n",
       " -0.05431323769404263,\n",
       " -0.04249334628357252,\n",
       " 0.014545959148368256,\n",
       " -0.005863124394994795,\n",
       " 0.00792848397114438,\n",
       " -0.0317555548270133,\n",
       " -0.01517024887284039,\n",
       " -0.00752789792490971,\n",
       " -0.010779408536349885,\n",
       " 0.05306465824509836,\n",
       " -0.004939695262136498,\n",
       " -0.013047663250841599,\n",
       " 0.004354423296197913,\n",
       " 0.023951930477143956,\n",
       " -0.02651151965133129,\n",
       " -0.02838438882474769,\n",
       " -0.17563360600903974,\n",
       " 0.014358672044762103,\n",
       " -0.010841837881326121,\n",
       " -0.0056602301879752235,\n",
       " 0.005826707354702204,\n",
       " 0.005987982619285989,\n",
       " -0.021808534452604715,\n",
       " 0.026761235168591118,\n",
       " 0.04773738145925454,\n",
       " -0.027302287008191678,\n",
       " 0.006695511159952252,\n",
       " 0.01822927001286994,\n",
       " -0.01359911889472855,\n",
       " 0.01390085902135567,\n",
       " 0.0028795380537913863,\n",
       " -0.008896133696001979,\n",
       " 0.0020549548405406387,\n",
       " -0.027302287008191678,\n",
       " -0.003862794882062404,\n",
       " -0.032192557447879286,\n",
       " -0.043908401502259935,\n",
       " 0.01371357191774952,\n",
       " -0.03427352692140997,\n",
       " 0.021829343923822606,\n",
       " -0.04440783626206982,\n",
       " -0.027094190433367634,\n",
       " -0.0033919761719754275,\n",
       " 0.0004464324363805288,\n",
       " -0.0410158589259412,\n",
       " 0.02736471542184536,\n",
       " 0.025283747810959798,\n",
       " -0.02172529470508803,\n",
       " -0.003272320548319346,\n",
       " 0.04124476683462825,\n",
       " -0.008256236868116424,\n",
       " 0.0102539647314853,\n",
       " -0.007788019109101045,\n",
       " -0.011466127605798255,\n",
       " -0.015087010987968818,\n",
       " -0.006950429510677835,\n",
       " 0.004281589681274009,\n",
       " -0.013703167182140572,\n",
       " 0.004513096911218184,\n",
       " -0.02963297013633707,\n",
       " 0.006071220969818839,\n",
       " -0.01147653327272976,\n",
       " -0.04403326205485752,\n",
       " 0.002009433656590219,\n",
       " 0.02393112100592606,\n",
       " 0.008438320672595546,\n",
       " 0.02393112100592606,\n",
       " 0.0002271180376993642,\n",
       " -0.0013656345871900313,\n",
       " -0.03926784844247727,\n",
       " -0.0559363913501992,\n",
       " 0.0039876531063535985,\n",
       " 0.056269346614975714,\n",
       " -0.0212778873486131,\n",
       " 0.021662866291434348,\n",
       " 0.0010066677162217869,\n",
       " 0.007569517333006775,\n",
       " 0.02784333884779224,\n",
       " 0.003985051922451362,\n",
       " -0.01739688371357376,\n",
       " -0.014587578090804042,\n",
       " 0.03319142324220884,\n",
       " 0.009660889213840005,\n",
       " 0.02397273994836185,\n",
       " 0.014431506125347287,\n",
       " 0.0159298029541965,\n",
       " 0.05035940090974066,\n",
       " 0.016429233988716162,\n",
       " 0.0189680136916856,\n",
       " 0.033794905358108196,\n",
       " 0.02278658891307126,\n",
       " 0.0003175100368650695,\n",
       " 0.015347131240837595,\n",
       " -0.06276196123960201,\n",
       " -0.008422713569182125,\n",
       " 0.006482212217323735,\n",
       " 0.008812894879807848,\n",
       " -0.010904267226302358,\n",
       " 0.031464222229962806,\n",
       " -0.016189923207065277,\n",
       " 0.08906538617875437,\n",
       " -0.04886110408089145,\n",
       " 0.060722614433797346,\n",
       " 0.03333708954073409,\n",
       " -0.04836167304637179,\n",
       " -0.05722659346686949,\n",
       " -0.029674589078772858,\n",
       " 0.03400300007028713,\n",
       " 0.017469716862836385,\n",
       " -0.004619746848193721,\n",
       " 0.021870962866258396,\n",
       " 0.054021901371701896,\n",
       " 0.04361706890520943,\n",
       " 0.06455159811608217,\n",
       " 0.009286315006627702,\n",
       " 0.018531011070819618,\n",
       " 0.03181798324066699,\n",
       " -0.00035929196074836414,\n",
       " 0.022266346544688592,\n",
       " 0.006627879912832822,\n",
       " 0.024846745190093816,\n",
       " 0.014868508746213269,\n",
       " -0.02160043787778067,\n",
       " 0.013578309423510657,\n",
       " -0.04168176945549423,\n",
       " -0.00619087682630556,\n",
       " -0.012787542066650264,\n",
       " -0.008339474752987996,\n",
       " 0.023494116522414964,\n",
       " -0.03964242264968957,\n",
       " -0.010649348409915497,\n",
       " 0.0501513024722715,\n",
       " 0.04586451042319302,\n",
       " -0.0022994684556572748,\n",
       " -0.018562225277646456,\n",
       " 0.003844586594746748,\n",
       " -0.034211098507756284,\n",
       " -0.0018026376737172924,\n",
       " -0.00938516092623525,\n",
       " 0.07295869899391554,\n",
       " -0.018884775806814028,\n",
       " 0.01694947635709883,\n",
       " -0.07195983692487622,\n",
       " -0.013078877457668439,\n",
       " 0.0027390727260867727,\n",
       " -0.019030442105339277,\n",
       " 0.0009956126846372812,\n",
       " 0.022994685487895305,\n",
       " -0.020632788152923073,\n",
       " -0.034918624254454876,\n",
       " -0.008693239488982407,\n",
       " 0.005275251245153973,\n",
       " -0.006971239447557007,\n",
       " -0.07071126120122218,\n",
       " -0.011684629847553803,\n",
       " -0.008146985281577371,\n",
       " 0.023244401005155135,\n",
       " 0.04357544996277364,\n",
       " -0.045656415711014094,\n",
       " 0.011570176824532836,\n",
       " 0.04066209418994679,\n",
       " 0.07129392639532318,\n",
       " -0.032858467977432325,\n",
       " 0.03650015896817566,\n",
       " 0.011320460375950447,\n",
       " 0.009770139869056501,\n",
       " 0.00777761390783082,\n",
       " 0.030236450389591312,\n",
       " 0.029071108825518617,\n",
       " 0.002623318878284046,\n",
       " 0.009676496317253425,\n",
       " 0.00980135407588334,\n",
       " -0.01701190477075251,\n",
       " -0.032587941126309486,\n",
       " -0.02628261360528935,\n",
       " 0.02517970045487033,\n",
       " -0.008662025282155567,\n",
       " -0.011934345364813635,\n",
       " -0.028696534618306315,\n",
       " 0.005977577418015764,\n",
       " -0.010997910778105434,\n",
       " -6.694048226837884e-05,\n",
       " -0.061929578665596056,\n",
       " -0.025824799650560358,\n",
       " -0.00660706997595365,\n",
       " -0.027073380962149743,\n",
       " 0.034564863243750694,\n",
       " -0.06313653917210454,\n",
       " 0.021392341302956624,\n",
       " -0.014056931918134983,\n",
       " -0.033565997449421146,\n",
       " -0.010654550777719969,\n",
       " 0.007642351413591958,\n",
       " -0.015617657160637876,\n",
       " -0.000994962388661722,\n",
       " -0.015315917034010754,\n",
       " 0.01614830426462949,\n",
       " 0.039080559476226004,\n",
       " 0.021579628406562777,\n",
       " 0.01919691973772754,\n",
       " 0.025158890983652437,\n",
       " 0.0321509385054435,\n",
       " 0.039746470005779036,\n",
       " -0.042472536812354626,\n",
       " 0.009031397121563397,\n",
       " -0.01008748709909704,\n",
       " 0.013026852848301148,\n",
       " 0.025616703075736314,\n",
       " 0.006294925113717583,\n",
       " 0.0004555366673498467,\n",
       " -0.029445683032730922,\n",
       " -0.02592884886929494,\n",
       " -0.005142589469156069,\n",
       " 0.07041992115359122,\n",
       " -0.0322549895868232,\n",
       " -0.026053705696602297,\n",
       " 0.0017818279696687602,\n",
       " 0.004221761520200009,\n",
       " -0.06267872335473043,\n",
       " 0.0010515386041966474,\n",
       " 0.021766913647523815,\n",
       " -0.007574719700811248,\n",
       " -0.11853188054534829,\n",
       " -0.02542941597213016,\n",
       " -0.05069235617451718,\n",
       " 0.008953360673173741,\n",
       " 0.03901813106257232,\n",
       " 0.01576332532180824,\n",
       " 0.015347131240837595,\n",
       " -0.022037440498646654,\n",
       " -0.0046509610550205605,\n",
       " 0.0020458506968828102,\n",
       " 0.0021290892802463004,\n",
       " 0.01919691973772754,\n",
       " -0.008937753569760322,\n",
       " 0.06925458331480876,\n",
       " 0.00707528773496903,\n",
       " -0.02037266603740918,\n",
       " 0.017969149760001163,\n",
       " 0.008693239488982407,\n",
       " 0.032359036942912665,\n",
       " -0.015898586884724546,\n",
       " 0.007902472132122014,\n",
       " -0.010612931835284183,\n",
       " 0.006804761815168748,\n",
       " 0.01707433318440619,\n",
       " -0.008994979615609527,\n",
       " -0.01717838240314077,\n",
       " -0.013047663250841599,\n",
       " 0.04723795042473488,\n",
       " 0.012693898514847188,\n",
       " 0.05718497079914347,\n",
       " 0.010508883547872161,\n",
       " -0.046738519390215214,\n",
       " 0.04836167304637179,\n",
       " 0.045698034653449876,\n",
       " 0.027094190433367634,\n",
       " -0.039517562097091986,\n",
       " -0.012652279572411402,\n",
       " 0.029716208021208643,\n",
       " 0.004125517250155975,\n",
       " 0.01070657538708726,\n",
       " 0.004437662112392043,\n",
       " 0.06530074653050678,\n",
       " 0.027343905950627467,\n",
       " 0.015617657160637876,\n",
       " -0.03256713165509159,\n",
       " -0.001920992589006936,\n",
       " -0.013047663250841599,\n",
       " -0.01764659923083359,\n",
       " -0.022162299188599126,\n",
       " -0.040141853684209236,\n",
       " -0.0006028301319016615,\n",
       " -0.009109432638630496,\n",
       " 0.015711299781118394,\n",
       " -0.015721706379372456,\n",
       " -0.022120678383518225,\n",
       " 0.015419965321422778,\n",
       " -0.027239858594538,\n",
       " 0.047987098839159484,\n",
       " -0.00724176490169601,\n",
       " 0.0031500637407610283,\n",
       " -0.010748194329523045,\n",
       " -0.0021655063205388916,\n",
       " -0.04457431203181297,\n",
       " -0.0008102765271654668,\n",
       " -0.07391594957109954,\n",
       " 0.037290926325036056,\n",
       " 0.03158907905727016,\n",
       " 0.023348450223889716,\n",
       " 0.0038341816263071623,\n",
       " -0.03953837156830988,\n",
       " 0.020247809210101823,\n",
       " -0.018884775806814028,\n",
       " 0.027884957790228027,\n",
       " -0.039247038971259376,\n",
       " 0.009728520926620715,\n",
       " 0.033982190599069234,\n",
       " -0.021225863670568366,\n",
       " 0.006763142872732962,\n",
       " -0.046738519390215214,\n",
       " 0.01668935424158494,\n",
       " -0.02438893309800994,\n",
       " -0.012808351537868157,\n",
       " 0.00513478591744936,\n",
       " -0.020050117370886723,\n",
       " -0.031651507470923844,\n",
       " -0.0189680136916856,\n",
       " -0.03227579905804109,\n",
       " 0.00039603403261341546,\n",
       " -0.015617657160637876,\n",
       " 0.0028847404215958596,\n",
       " -0.028259531997440333,\n",
       " -0.0026012088151150347,\n",
       " 0.0003755495056564926,\n",
       " 0.02576237123690668,\n",
       " 0.02303630443033109,\n",
       " -0.05726821240930527,\n",
       " 0.03296251533352179,\n",
       " 0.0059983873548949355,\n",
       " 0.004258178560492601,\n",
       " -0.0062324962344026255,\n",
       " -0.03787359896971752,\n",
       " 0.04715471253986331,\n",
       " 0.025221319397306118,\n",
       " -0.03444000269115311,\n",
       " 0.011060339191759113,\n",
       " -0.046780138332651,\n",
       " 0.022869826797942833,\n",
       " -0.07258412851199347,\n",
       " -0.042743059938187236,\n",
       " 0.012402563123829015,\n",
       " -0.030881549585281342,\n",
       " -0.047404426194478023,\n",
       " 0.016283565827545796,\n",
       " 0.001032029608514553,\n",
       " 0.03539724954304688,\n",
       " 0.06226253020508234,\n",
       " -0.03714526002651081,\n",
       " -0.045073743066332626,\n",
       " 0.012579445491826219,\n",
       " -0.013796810733943649,\n",
       " 0.0011263233398778683,\n",
       " -0.022266346544688592,\n",
       " 0.027052571490931848,\n",
       " -0.026157754915336878,\n",
       " -0.0035558523876308102,\n",
       " -0.03949675262587409,\n",
       " -0.019269754749635278,\n",
       " -0.0032983326201723516,\n",
       " -0.029903495124814796,\n",
       " 0.051774459853718306,\n",
       " -0.005826707354702204,\n",
       " -0.006648689384050715,\n",
       " -0.02274496810799036,\n",
       " 0.0643434959533228,\n",
       " 0.03387814324297977,\n",
       " -0.031859605908393,\n",
       " 0.03899732159135443,\n",
       " -0.023702213097239012,\n",
       " -0.02884220277947668,\n",
       " -0.0018260485616680615,\n",
       " -0.0027676859818420146,\n",
       " 0.038414648946672965,\n",
       " -0.0041931484972754065,\n",
       " 0.006149257418208496,\n",
       " -0.01026957183489872,\n",
       " 0.020632788152923073,\n",
       " 0.041411242604371394,\n",
       " -0.02015416472697619,\n",
       " -0.0074654690455947526,\n",
       " 0.024201645994403786,\n",
       " -0.02141315077417452,\n",
       " 0.06138852496335038,\n",
       " 0.017469716862836385,\n",
       " -0.01675178451788373,\n",
       " -0.00913544540897542,\n",
       " 0.035896680577566537,\n",
       " -0.031838796437175104,\n",
       " -0.025845609121778253,\n",
       " -0.018895180542422972,\n",
       " 0.0006369709616568165,\n",
       " 0.021433960245392413,\n",
       " 0.06188795599787004,\n",
       " 0.004367429215709096,\n",
       " -0.014535554412759309,\n",
       " 0.038227363705711934,\n",
       " -0.01052449065128558,\n",
       " -0.019425825783769474,\n",
       " 0.04311763414539954,\n",
       " -0.011715844054380644,\n",
       " -0.02086169419896501,\n",
       " -0.02086169419896501,\n",
       " -0.03233822747169477,\n",
       " 0.033940571656633445,\n",
       " 0.01063894367430655,\n",
       " 0.00194050170110435,\n",
       " 0.06113881130873566,\n",
       " 0.01861424895569119,\n",
       " -0.012579445491826219,\n",
       " -0.00863081014400617,\n",
       " -0.01323495035444775,\n",
       " -0.036083965818527575,\n",
       " -0.005873529130603741,\n",
       " -0.027302287008191678,\n",
       " 0.006560248200052112,\n",
       " -0.013141306802644675,\n",
       " 0.06151338551594797,\n",
       " -0.07753682736533475,\n",
       " -0.003311338772514174,\n",
       " -0.01984202079606268,\n",
       " -0.01505579584981942,\n",
       " 0.019051253439202286,\n",
       " 0.027343905950627467,\n",
       " 0.022703349165554575,\n",
       " -0.033753282690382184,\n",
       " 0.03323304218464463,\n",
       " -0.028530056985918054,\n",
       " 0.013536690481074871,\n",
       " 0.026636376478638646,\n",
       " -0.05909946077764077,\n",
       " -0.03674987634808061,\n",
       " -0.01858303474886435,\n",
       " 0.015825753735461922,\n",
       " 0.03991294577552218,\n",
       " -0.04039156733882395,\n",
       " 0.0010736489001962981,\n",
       " -0.0039070154740617055,\n",
       " 0.042618203110879875,\n",
       " -0.04482402941171791,\n",
       " -0.018811940794906286,\n",
       " -0.014285837964176921,\n",
       " 0.022557682867029322,\n",
       " 0.027926576732663813,\n",
       " 0.007418647269693214,\n",
       " 0.03269199220768918,\n",
       " 0.024555410730398197,\n",
       " -0.036208826371125165,\n",
       " -0.018510201599601723,\n",
       " 0.003818574290063103,\n",
       " 0.03527238899044929,\n",
       " -0.015024581642992581,\n",
       " 0.06317815811454032,\n",
       " -0.02830115093987612,\n",
       " 0.05069235617451718,\n",
       " -0.00811056870694606,\n",
       " -0.007657958517005377,\n",
       " -0.015825753735461922,\n",
       " 0.00986898578866405,\n",
       " 0.03570939161131527,\n",
       " -0.058267074478344595,\n",
       " 0.006378163929911712,\n",
       " -0.017448907391618494,\n",
       " -0.030839930642845556,\n",
       " 0.02091371787700974,\n",
       " 0.006300127481522057,\n",
       " -0.022890636269160724,\n",
       " -0.032109319563007714,\n",
       " 0.015784134793026136,\n",
       " -0.007319801350085665,\n",
       " 0.007356218390378257,\n",
       " -0.048111955666466845,\n",
       " 0.03618801689990727,\n",
       " -0.013006043377083255,\n",
       " 0.06492616859800425,\n",
       " 0.02617856438655477,\n",
       " -0.032733611150124964,\n",
       " -0.0006860687734728115,\n",
       " 0.022516062061948422,\n",
       " -0.014878913481822215,\n",
       " 0.012756327859823424,\n",
       " 0.033565997449421146,\n",
       " 0.008760871201763117,\n",
       " 0.04349220835261184,\n",
       " -0.015034986378601527,\n",
       " 0.06030642128414925,\n",
       " 0.04773738145925454,\n",
       " 0.014681221642607116,\n",
       " -0.042347676259757036,\n",
       " 0.03770712319997437,\n",
       " -0.021662866291434348,\n",
       " -0.03256713165509159,\n",
       " -0.004861659279408121,\n",
       " 0.0037743539308944408,\n",
       " -0.042347676259757036,\n",
       " 0.0041931484972754065,\n",
       " 0.02363978468358533,\n",
       " -0.011018720249323327,\n",
       " -0.031922034322046676,\n",
       " 0.0003566907477422976,\n",
       " 0.006523831625420799,\n",
       " -0.014525149677150363,\n",
       " 0.009442387903407014,\n",
       " 0.004981314670233563,\n",
       " 0.04134881419071772,\n",
       " 0.01634599610384459,\n",
       " 0.03537644007182898,\n",
       " 0.05144150458894179,\n",
       " -0.028883821721912464,\n",
       " -0.015430370057031724,\n",
       " -0.07254250956955768,\n",
       " 0.043991643112421736,\n",
       " 0.006846381223265813,\n",
       " 0.021350720497875723,\n",
       " 0.013120496400104225,\n",
       " -0.026345042018943027,\n",
       " -0.03427352692140997,\n",
       " 0.033982190599069234,\n",
       " 0.04105747786837698,\n",
       " 0.023369259695107607,\n",
       " 0.04752928674707561,\n",
       " 0.019540279738113002,\n",
       " -0.005639420716757331,\n",
       " -0.05181607879615409,\n",
       " -0.0356261537264437,\n",
       " -0.024305693350493252,\n",
       " 0.03789440844093541,\n",
       " 0.017896316610738535,\n",
       " -0.001989924777323444,\n",
       " 0.020299832888146553,\n",
       " 0.057143351856707686,\n",
       " -0.004957904015113433,\n",
       " 0.005384501900370469,\n",
       " -0.003126652852810259,\n",
       " -0.02297387601667741,\n",
       " -0.07100259379827269,\n",
       " -0.02830115093987612,\n",
       " -0.008932550270633291,\n",
       " 0.025616703075736314,\n",
       " -0.025824799650560358,\n",
       " -0.01845817792155699,\n",
       " -0.008688037121177933,\n",
       " -0.03242146535656634,\n",
       " 0.0019574095128842076,\n",
       " -0.015940207689805447,\n",
       " -0.03839383947545508,\n",
       " 0.008859717121370665,\n",
       " 0.038685175797795804,\n",
       " 0.000178182799877259,\n",
       " 0.002817108941645789,\n",
       " 0.05069235617451718,\n",
       " -0.00831346291396563,\n",
       " -0.013661548239704786,\n",
       " -0.006492616952932681,\n",
       " 0.027447955169362045,\n",
       " 0.029591351193901286,\n",
       " -1.5622493939318663e-07,\n",
       " 0.030590215125585723,\n",
       " 0.004284190865176246,\n",
       " 0.01601304083906807,\n",
       " -0.015399155850204885,\n",
       " 0.00992101039803134,\n",
       " 0.02809305436505207,\n",
       " -0.022307965487124378,\n",
       " -0.007709982660711389,\n",
       " -0.02388950020084516,\n",
       " 0.014525149677150363,\n",
       " 0.05522886187821038,\n",
       " 0.039392705269784625,\n",
       " -4.9544897575149384e-05,\n",
       " -0.0006490015536199805,\n",
       " -0.021642056820216457,\n",
       " 0.042659822053315664,\n",
       " 0.03835222053301929,\n",
       " -0.015347131240837595,\n",
       " -0.016231542149501062,\n",
       " -0.0008109268231410259,\n",
       " 0.030153210642074626,\n",
       " 0.025783180708124572,\n",
       " 0.014826889803777483,\n",
       " -0.009728520926620715,\n",
       " -0.0271982377894571,\n",
       " 0.054562955073947574,\n",
       " -0.03982970789065061,\n",
       " 0.0013747388472631792,\n",
       " -0.049818350932785214,\n",
       " -0.004390840336490505,\n",
       " 0.01865586976077209,\n",
       " 0.02511727204121665,\n",
       " -0.013786405998334701,\n",
       " 0.01607546925272175,\n",
       " 0.0015529215743808635,\n",
       " -0.016137899529020543,\n",
       " -0.08236466939136869,\n",
       " -0.00551976486027061,\n",
       " 0.033212232713426736,\n",
       " 0.010373620122310741,\n",
       " -0.027947386203881708,\n",
       " -0.017761053185177116,\n",
       " -0.025824799650560358,\n",
       " 0.03514753216314193,\n",
       " 0.017604980288397805,\n",
       " 0.00876607356956759,\n",
       " -0.011851106548619506,\n",
       " -0.021298696819830994,\n",
       " 0.04607260886066218,\n",
       " 0.006362556360837014,\n",
       " 0.015430370057031724,\n",
       " -0.0356053442552258,\n",
       " -0.05976537130719381,\n",
       " -0.005951565578993397,\n",
       " -0.041993915249052854,\n",
       " -0.009000181983414,\n",
       " -0.08765032723477673,\n",
       " 0.009957426972662652,\n",
       " -0.03718687896894659,\n",
       " -0.024784316776440135,\n",
       " 0.0147540557231923,\n",
       " 0.004526103296390646,\n",
       " 0.05040101985217645,\n",
       " -0.01793793555317432,\n",
       " -0.0029939913096429945,\n",
       " -0.01791712608195643,\n",
       " 0.007793221476905518,\n",
       " -0.032587941126309486,\n",
       " 0.01867667923198998,\n",
       " -0.02984106671116112,\n",
       " -0.006331342154010175,\n",
       " 0.016054659781503857,\n",
       " -0.031256123792493644,\n",
       " -0.014004907308767692,\n",
       " -0.015711299781118394,\n",
       " -0.00573826663636488,\n",
       " -0.06788114331326689,\n",
       " -0.004666568624095259,\n",
       " -0.023702213097239012,\n",
       " -0.04047480894898575,\n",
       " 0.03306656641490148,\n",
       " -0.04290953943322061,\n",
       " 0.032234180115605304,\n",
       " -0.04648880201031027,\n",
       " 0.010300786973048117,\n",
       " 0.0720430748097478,\n",
       " 0.0005534071720978871,\n",
       " 0.02017497419819408,\n",
       " 0.010945886168738143,\n",
       " 0.00777761390783082,\n",
       " 0.0008044238051777746,\n",
       " 0.01830210502477768,\n",
       " -0.031734745355795416,\n",
       " -0.03325385165586252,\n",
       " -0.016668544770367045,\n",
       " 0.0066903087921477795,\n",
       " -0.01695988109270778,\n",
       " 0.021621247348998562,\n",
       " 0.005909946170896333,\n",
       " 0.01845817792155699,\n",
       " 0.03044454696441536,\n",
       " -0.02755200252545151,\n",
       " -0.1345137034522993,\n",
       " -0.06076423710152336,\n",
       " -0.009057408960585763,\n",
       " 0.06933782119968032,\n",
       " 0.06267872335473043,\n",
       " 0.03614639795747148,\n",
       " 0.06933782119968032,\n",
       " 0.01045685893850487,\n",
       " 0.01681421293153741,\n",
       " 0.032733611150124964,\n",
       " -0.0007933686571779492,\n",
       " -0.005514562492466136,\n",
       " 0.05993184707693695,\n",
       " 0.016543687943059687,\n",
       " -0.051399885646506,\n",
       " 0.006534236361029746,\n",
       " 0.0494853956680087,\n",
       " -0.0004389539744539386,\n",
       " -0.014972557033625291,\n",
       " -0.04690499515995836,\n",
       " -0.021579628406562777,\n",
       " 0.029424873561513028,\n",
       " 0.020112545784540404,\n",
       " 0.014192194412373845,\n",
       " -0.02977863829750744,\n",
       " -0.04424135676703645,\n",
       " 0.031256123792493644,\n",
       " 0.003953837249963244,\n",
       " 0.06138852496335038,\n",
       " -0.012485801940023144,\n",
       " -0.014795675596950643,\n",
       " 0.01450434020593247,\n",
       " -0.006497819320737154,\n",
       " -0.02409759677566921,\n",
       " 0.0061180427457203776,\n",
       " -0.01986283026728057,\n",
       " -0.01756336134596202,\n",
       " 0.054562955073947574,\n",
       " 0.002853525981938381,\n",
       " 0.01279794680225921,\n",
       " -0.05660230187975224,\n",
       " 0.009203076190433573,\n",
       " 0.0367706858192985,\n",
       " -0.020611978681705178,\n",
       " 0.026969331743415162,\n",
       " 0.05835031236321617,\n",
       " 0.001944403476957705,\n",
       " -0.004429858560685332,\n",
       " -0.021829343923822606,\n",
       " -0.04224362890366758,\n",
       " 0.024347314155574153,\n",
       " -0.14808161279681378,\n",
       " 0.04544831727354493,\n",
       " -0.03539724954304688,\n",
       " 0.03810250687840457,\n",
       " 0.08057503996546897,\n",
       " 0.03982970789065061,\n",
       " -0.0218501533950405,\n",
       " -0.04407488099729331,\n",
       " 0.008490345281962835,\n",
       " -0.023015494959113196,\n",
       " -0.03115207643640418,\n",
       " 0.005452133613151179,\n",
       " -0.019914853945325304,\n",
       " -0.0065186292576163265,\n",
       " -0.0030694263412997746,\n",
       " -0.030298878803244993,\n",
       " -0.00511137526232923,\n",
       " 0.019810804726590726,\n",
       " -0.011663819445013353,\n",
       " -0.04648880201031027,\n",
       " -0.015981826632241233,\n",
       " 0.019134491324073858,\n",
       " -0.01634599610384459,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(texts[0].page_content) # Create embeddings from the first chunk\n",
    "\n",
    "query_result # Print the embeddings \n",
    "\n",
    "# You should see the vector representation of that text (i.e., the embedding) below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Store the resulting vector embeddings in a pinecone vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Import the os module, which allows you to interact with the operating system.\n",
    "import pinecone # Import the pinecone module, which allows you to interact with the Pinecone API.\n",
    "from langchain.vectorstores import Pinecone # Import the Pinecone class, which allows you to create vector stores.\n",
    "\n",
    "# Create a new vector store instance\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\"), # Specify the Pinecone API key\n",
    "    environment=os.environ.get(\"PINECONE_ENV\"), # Specify the Pinecone environment\n",
    ")\n",
    "\n",
    "# Create an index in the vector store to store the embeddings.\n",
    "index_name = \"index-name\"\n",
    "search = Pinecone.from_documents(texts, embeddings, index_name=index_name, # Specify the index name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Query the vector database via similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's so interesting about gradient descent?\" # Specify the query\n",
    "result = search.similarity_search(query) # Search for similar documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8:** Display the results of the similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='that tells you how long it takes you to get down each path.', metadata={}),\n",
       " Document(page_content='Gradient descent is like a game where you have to find the best way down a mountain. You have to try', metadata={}),\n",
       " Document(page_content='Gradient descent is like this game, but instead of a mountain, it is used to find the best way to', metadata={}),\n",
       " Document(page_content='different paths to see which one is the fastest way to the bottom.', metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result # Print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***V. SETTING UP AND USING --> Agents***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Call the class imports necessary to run the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent # Import the create_python_agent function, which allows you to create a Python agent.\n",
    "from langchain.tools.python.tool import PythonREPLTool # Import the PythonREPLTool class, which allows you to create a Python REPL tool.\n",
    "from langchain.tools.python.tool import PythonREPL # Import the PythonREPL class, which allows you to create a Python REPL.\n",
    "from langchain.llms.openai import OpenAI # Import the OpenAI class, which allows you to create a language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Create a Python Agent executer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executer = create_python_agent( # Create a new agent executer instance\n",
    "    llm = OpenAI(temperature=0, max_tokens=1000), # Specify the language model to use and limit the number of tokens to 1000\n",
    "    tool=PythonREPLTool(), # Specify the tool to use\n",
    "    verbose=True, # Specify whether to print the intermediate results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Have the agent execute python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to solve a quadratic equation.\n",
      "Action: Python REPL\n",
      "Action Input: import numpy as np\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I can use the numpy function to solve the equation.\n",
      "Action: Python REPL\n",
      "Action Input: np.roots([1,2,1])\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The roots of the equation are -1 and -1.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The roots of the equation are -1 and -1.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.run(\"Find the roots (zeros) if the quadratic equation x^2 + 2x + 1 = 0.\") # Call the agent executer with a prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
